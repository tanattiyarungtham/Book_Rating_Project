{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "53cf0dc4-7f1a-4263-9225-2117aaf58e42",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import missingno as ms\n",
    "from yellowbrick.regressor import PredictionError\n",
    "import smogn\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.linear_model import Lasso\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.linear_model import ElasticNet\n",
    "from sklearn.dummy import DummyRegressor\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "from lightgbm import LGBMRegressor\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from lazypredict.Supervised import LazyRegressor\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import ExtraTreesRegressor, RandomForestRegressor, BaggingRegressor\n",
    "from lightgbm import LGBMRegressor\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ba253567-3c19-481d-b422-70db2c7d9a14",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: smogn in c:\\users\\tanattiya\\anaconda3\\envs\\myenv\\lib\\site-packages (0.1.2)\n",
      "Requirement already satisfied: lightgbm in c:\\users\\tanattiya\\anaconda3\\envs\\myenv\\lib\\site-packages (4.4.0)\n",
      "Requirement already satisfied: numpy in c:\\users\\tanattiya\\anaconda3\\envs\\myenv\\lib\\site-packages (from smogn) (2.0.0)\n",
      "Requirement already satisfied: pandas in c:\\users\\tanattiya\\anaconda3\\envs\\myenv\\lib\\site-packages (from smogn) (2.2.2)\n",
      "Requirement already satisfied: tqdm in c:\\users\\tanattiya\\anaconda3\\envs\\myenv\\lib\\site-packages (from smogn) (4.66.4)\n",
      "Requirement already satisfied: scipy in c:\\users\\tanattiya\\anaconda3\\envs\\myenv\\lib\\site-packages (from lightgbm) (1.14.0)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\tanattiya\\anaconda3\\envs\\myenv\\lib\\site-packages (from pandas->smogn) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\tanattiya\\anaconda3\\envs\\myenv\\lib\\site-packages (from pandas->smogn) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\tanattiya\\anaconda3\\envs\\myenv\\lib\\site-packages (from pandas->smogn) (2024.1)\n",
      "Requirement already satisfied: colorama in c:\\users\\tanattiya\\anaconda3\\envs\\myenv\\lib\\site-packages (from tqdm->smogn) (0.4.6)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\tanattiya\\anaconda3\\envs\\myenv\\lib\\site-packages (from python-dateutil>=2.8.2->pandas->smogn) (1.16.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install smogn lightgbm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e582f770-f5e7-4d4f-9af9-8a18e4753aa3",
   "metadata": {},
   "source": [
    "Import processed_data after the EDA process in Exploratory Data Analysis file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ab0e0ecd-59bb-465b-a2e9-bb8c72d4519e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"processed_data.csv\",sep=\",\",index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "88610aec-f3ad-430e-895f-7ba8f1d60cab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>average_rating</th>\n",
       "      <th>num_pages</th>\n",
       "      <th>ratings_count</th>\n",
       "      <th>text_reviews_count</th>\n",
       "      <th>publisher_average_rating</th>\n",
       "      <th>author_average_rating</th>\n",
       "      <th>author_average_page</th>\n",
       "      <th>author_book_count</th>\n",
       "      <th>language_average_rating</th>\n",
       "      <th>publication_year</th>\n",
       "      <th>review_weight</th>\n",
       "      <th>rating_weight_</th>\n",
       "      <th>rate_per_pages</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4.57</td>\n",
       "      <td>652</td>\n",
       "      <td>2095690</td>\n",
       "      <td>27591</td>\n",
       "      <td>4.06</td>\n",
       "      <td>4.55</td>\n",
       "      <td>902.00</td>\n",
       "      <td>6</td>\n",
       "      <td>3.93</td>\n",
       "      <td>2006.00</td>\n",
       "      <td>126090.87</td>\n",
       "      <td>9577303.30</td>\n",
       "      <td>2979.64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.49</td>\n",
       "      <td>870</td>\n",
       "      <td>2153167</td>\n",
       "      <td>29221</td>\n",
       "      <td>4.06</td>\n",
       "      <td>4.55</td>\n",
       "      <td>902.00</td>\n",
       "      <td>6</td>\n",
       "      <td>3.93</td>\n",
       "      <td>2004.00</td>\n",
       "      <td>131202.29</td>\n",
       "      <td>9667719.83</td>\n",
       "      <td>3906.30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.42</td>\n",
       "      <td>352</td>\n",
       "      <td>6333</td>\n",
       "      <td>244</td>\n",
       "      <td>3.98</td>\n",
       "      <td>4.51</td>\n",
       "      <td>728.55</td>\n",
       "      <td>11</td>\n",
       "      <td>3.93</td>\n",
       "      <td>2003.00</td>\n",
       "      <td>1078.48</td>\n",
       "      <td>27991.86</td>\n",
       "      <td>1555.84</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.56</td>\n",
       "      <td>435</td>\n",
       "      <td>2339585</td>\n",
       "      <td>36325</td>\n",
       "      <td>4.06</td>\n",
       "      <td>4.55</td>\n",
       "      <td>902.00</td>\n",
       "      <td>6</td>\n",
       "      <td>3.93</td>\n",
       "      <td>2004.00</td>\n",
       "      <td>165642.00</td>\n",
       "      <td>10668507.60</td>\n",
       "      <td>1983.60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4.78</td>\n",
       "      <td>2690</td>\n",
       "      <td>41428</td>\n",
       "      <td>164</td>\n",
       "      <td>3.98</td>\n",
       "      <td>4.55</td>\n",
       "      <td>902.00</td>\n",
       "      <td>6</td>\n",
       "      <td>3.93</td>\n",
       "      <td>2004.00</td>\n",
       "      <td>783.92</td>\n",
       "      <td>198025.84</td>\n",
       "      <td>12858.20</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   average_rating  num_pages  ratings_count  text_reviews_count  \\\n",
       "0            4.57        652        2095690               27591   \n",
       "1            4.49        870        2153167               29221   \n",
       "2            4.42        352           6333                 244   \n",
       "3            4.56        435        2339585               36325   \n",
       "4            4.78       2690          41428                 164   \n",
       "\n",
       "   publisher_average_rating  author_average_rating  author_average_page  \\\n",
       "0                      4.06                   4.55               902.00   \n",
       "1                      4.06                   4.55               902.00   \n",
       "2                      3.98                   4.51               728.55   \n",
       "3                      4.06                   4.55               902.00   \n",
       "4                      3.98                   4.55               902.00   \n",
       "\n",
       "   author_book_count  language_average_rating  publication_year  \\\n",
       "0                  6                     3.93           2006.00   \n",
       "1                  6                     3.93           2004.00   \n",
       "2                 11                     3.93           2003.00   \n",
       "3                  6                     3.93           2004.00   \n",
       "4                  6                     3.93           2004.00   \n",
       "\n",
       "   review_weight  rating_weight_  rate_per_pages  \n",
       "0      126090.87      9577303.30         2979.64  \n",
       "1      131202.29      9667719.83         3906.30  \n",
       "2        1078.48        27991.86         1555.84  \n",
       "3      165642.00     10668507.60         1983.60  \n",
       "4         783.92       198025.84        12858.20  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9ed589de-6509-4722-9fbf-2ef375198571",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 11127 entries, 0 to 11126\n",
      "Data columns (total 13 columns):\n",
      " #   Column                    Non-Null Count  Dtype  \n",
      "---  ------                    --------------  -----  \n",
      " 0   average_rating            11127 non-null  float64\n",
      " 1   num_pages                 11127 non-null  int64  \n",
      " 2   ratings_count             11127 non-null  int64  \n",
      " 3   text_reviews_count        11127 non-null  int64  \n",
      " 4   publisher_average_rating  11127 non-null  float64\n",
      " 5   author_average_rating     11127 non-null  float64\n",
      " 6   author_average_page       11127 non-null  float64\n",
      " 7   author_book_count         11127 non-null  int64  \n",
      " 8   language_average_rating   11127 non-null  float64\n",
      " 9   publication_year          11127 non-null  float64\n",
      " 10  review_weight             11127 non-null  float64\n",
      " 11  rating_weight_            11127 non-null  float64\n",
      " 12  rate_per_pages            11127 non-null  float64\n",
      "dtypes: float64(9), int64(4)\n",
      "memory usage: 1.2 MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2cac87d2-e025-46fd-a8f5-329639d06099",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>average_rating</th>\n",
       "      <th>num_pages</th>\n",
       "      <th>ratings_count</th>\n",
       "      <th>text_reviews_count</th>\n",
       "      <th>publisher_average_rating</th>\n",
       "      <th>author_average_rating</th>\n",
       "      <th>author_average_page</th>\n",
       "      <th>author_book_count</th>\n",
       "      <th>language_average_rating</th>\n",
       "      <th>publication_year</th>\n",
       "      <th>review_weight</th>\n",
       "      <th>rating_weight_</th>\n",
       "      <th>rate_per_pages</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4.57</td>\n",
       "      <td>652</td>\n",
       "      <td>2095690</td>\n",
       "      <td>27591</td>\n",
       "      <td>4.06</td>\n",
       "      <td>4.55</td>\n",
       "      <td>902.00</td>\n",
       "      <td>6</td>\n",
       "      <td>3.93</td>\n",
       "      <td>2006.00</td>\n",
       "      <td>126090.87</td>\n",
       "      <td>9577303.30</td>\n",
       "      <td>2979.64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.49</td>\n",
       "      <td>870</td>\n",
       "      <td>2153167</td>\n",
       "      <td>29221</td>\n",
       "      <td>4.06</td>\n",
       "      <td>4.55</td>\n",
       "      <td>902.00</td>\n",
       "      <td>6</td>\n",
       "      <td>3.93</td>\n",
       "      <td>2004.00</td>\n",
       "      <td>131202.29</td>\n",
       "      <td>9667719.83</td>\n",
       "      <td>3906.30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.42</td>\n",
       "      <td>352</td>\n",
       "      <td>6333</td>\n",
       "      <td>244</td>\n",
       "      <td>3.98</td>\n",
       "      <td>4.51</td>\n",
       "      <td>728.55</td>\n",
       "      <td>11</td>\n",
       "      <td>3.93</td>\n",
       "      <td>2003.00</td>\n",
       "      <td>1078.48</td>\n",
       "      <td>27991.86</td>\n",
       "      <td>1555.84</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.56</td>\n",
       "      <td>435</td>\n",
       "      <td>2339585</td>\n",
       "      <td>36325</td>\n",
       "      <td>4.06</td>\n",
       "      <td>4.55</td>\n",
       "      <td>902.00</td>\n",
       "      <td>6</td>\n",
       "      <td>3.93</td>\n",
       "      <td>2004.00</td>\n",
       "      <td>165642.00</td>\n",
       "      <td>10668507.60</td>\n",
       "      <td>1983.60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4.78</td>\n",
       "      <td>2690</td>\n",
       "      <td>41428</td>\n",
       "      <td>164</td>\n",
       "      <td>3.98</td>\n",
       "      <td>4.55</td>\n",
       "      <td>902.00</td>\n",
       "      <td>6</td>\n",
       "      <td>3.93</td>\n",
       "      <td>2004.00</td>\n",
       "      <td>783.92</td>\n",
       "      <td>198025.84</td>\n",
       "      <td>12858.20</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   average_rating  num_pages  ratings_count  text_reviews_count  \\\n",
       "0            4.57        652        2095690               27591   \n",
       "1            4.49        870        2153167               29221   \n",
       "2            4.42        352           6333                 244   \n",
       "3            4.56        435        2339585               36325   \n",
       "4            4.78       2690          41428                 164   \n",
       "\n",
       "   publisher_average_rating  author_average_rating  author_average_page  \\\n",
       "0                      4.06                   4.55               902.00   \n",
       "1                      4.06                   4.55               902.00   \n",
       "2                      3.98                   4.51               728.55   \n",
       "3                      4.06                   4.55               902.00   \n",
       "4                      3.98                   4.55               902.00   \n",
       "\n",
       "   author_book_count  language_average_rating  publication_year  \\\n",
       "0                  6                     3.93           2006.00   \n",
       "1                  6                     3.93           2004.00   \n",
       "2                 11                     3.93           2003.00   \n",
       "3                  6                     3.93           2004.00   \n",
       "4                  6                     3.93           2004.00   \n",
       "\n",
       "   review_weight  rating_weight_  rate_per_pages  \n",
       "0      126090.87      9577303.30         2979.64  \n",
       "1      131202.29      9667719.83         3906.30  \n",
       "2        1078.48        27991.86         1555.84  \n",
       "3      165642.00     10668507.60         1983.60  \n",
       "4         783.92       198025.84        12858.20  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16c97576-59ce-4ea6-a687-7d61dbfc81b3",
   "metadata": {},
   "source": [
    "We will explore the relationships between variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9033fe39-9462-4c0e-b36f-b56f423999c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.pairplot(df)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c3ddb54-aeeb-4e40-b1a9-035a942117f9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98187a21-153d-4eaa-8bba-35e57cb826c3",
   "metadata": {},
   "source": [
    "Check the correlations of the variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "408106b1-8606-4c4a-868d-3e140c5a92b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "corr = df.corr()\n",
    "\n",
    "mask = np.zeros_like(corr, dtype=bool)\n",
    "mask[np.triu_indices_from(mask)] = True\n",
    "\n",
    "plt.figure(figsize=(12, 8)) \n",
    "\n",
    "sns.heatmap(corr, mask=mask, annot=True, center=0)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10bc2bcf-1efa-4a78-a3cd-1e2209b24576",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separate features and target\n",
    "X = df.drop(columns=['average_rating'])\n",
    "y = df['average_rating']\n",
    "\n",
    "# Display the first few rows of the dataset\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c36851ef-7280-4d87-80f4-01ee8cd23539",
   "metadata": {},
   "outputs": [],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be3b7556-019e-4f7d-907c-b8566c91cf6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15b96e8f-3e41-44bf-95a4-b26f0f90f09c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Identify features to normalize\n",
    "features_to_normalize = ['ratings_count', 'text_reviews_count','num_pages','author_average_page']\n",
    "\n",
    "# Initialize the scaler\n",
    "scaler = StandardScaler()\n",
    "\n",
    "# Fit and transform the specific features\n",
    "X[features_to_normalize] = scaler.fit_transform(X[features_to_normalize])\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8511f75-67f3-4996-bf3c-ca75c43ffeed",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Train a Random Forest Regressor\n",
    "model_smogn = RandomForestRegressor()\n",
    "model_smogn.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions\n",
    "y_pred = model_smogn.predict(X_test)\n",
    "\n",
    "mae = mean_absolute_error(y_test, y_pred)\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "# Evaluate the model\n",
    "mse_smogn = mean_squared_error(y_test, y_pred)\n",
    "print(f'Mean Squared Error model smogn: {mse_smogn}, \\nmae: {mae}, \\nr2:{r2}')\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "raw",
   "id": "bf61240c-0b67-4f24-8f73-c94c88f77ecc",
   "metadata": {},
   "source": [
    "# Create a linear regression model\n",
    "model_og = LinearRegression()\n",
    "\n",
    "# Train the model on the training data\n",
    "model_og.fit(X_train, y_train)\n",
    "\n",
    "y_pred = model_og.predict(X_test)\n",
    "\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "# Calculate the Mean Squared Error\n",
    "mse_og = mean_squared_error(y_test, y_pred)\n",
    "print(f'Mean Squared Error original value: {mse_og}')"
   ]
  },
  {
   "cell_type": "raw",
   "id": "89f250dd-8b6e-4aef-9af4-e030eebdaae1",
   "metadata": {},
   "source": [
    "# Train a baseline model (mean model)\n",
    "dummy = DummyRegressor(strategy=\"mean\")\n",
    "dummy.fit(X_train, y_train)\n",
    "y_dummy_pred = dummy.predict(X_test)\n",
    "baseline_mse = mean_squared_error(y_test, y_dummy_pred)\n",
    "print(f'Baseline Mean Squared Error: {baseline_mse}')"
   ]
  },
  {
   "cell_type": "raw",
   "id": "c9f33733-3766-4892-9ef7-0f35b27a051f",
   "metadata": {},
   "source": [
    "\n",
    "# Apply Lasso (L1) regularization\n",
    "lasso = Lasso(alpha=0.1)  # alpha is the regularization strength\n",
    "lasso.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions\n",
    "y_pred = lasso.predict(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "mse_l1 = mean_squared_error(y_test, y_pred)\n",
    "print(f'Mean Squared Error with L1 Lasso: {mse_l1}')"
   ]
  },
  {
   "cell_type": "raw",
   "id": "f5edd9c5-14d2-447c-886f-72c38c67c55f",
   "metadata": {},
   "source": [
    "\n",
    "# Apply Ridge (L2) regularization\n",
    "ridge = Ridge(alpha=0.1)  # alpha is the regularization strength\n",
    "ridge.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions\n",
    "y_pred = ridge.predict(X_test)\n",
    "\n",
    "# Calculate and print the MSE\n",
    "mse_l2 = mean_squared_error(y_test, y_pred)\n",
    "print(f'Mean Squared Error with Ridge: {mse_l2}')"
   ]
  },
  {
   "cell_type": "raw",
   "id": "51103328-b13d-43b4-bcdd-4e2864dd4293",
   "metadata": {},
   "source": [
    "\n",
    "# Apply ElasticNet (L1 and L2) regularization\n",
    "elastic_net = ElasticNet(alpha=0.1, l1_ratio=0.5)  # alpha is the regularization strength, l1_ratio is the balance between L1 and L2\n",
    "elastic_net.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions\n",
    "y_pred = elastic_net.predict(X_test)\n",
    "\n",
    "# Calculate and print the MSE\n",
    "mse_elastic = mean_squared_error(y_test, y_pred)\n",
    "print(f'Mean Squared Error with ElasticNet: {mse_elastic}')"
   ]
  },
  {
   "cell_type": "raw",
   "id": "7a825b91-5451-4ee7-81ff-c8f87bc99a1d",
   "metadata": {},
   "source": [
    "#Compare the MSE of different models with the baseline\n",
    "print(f'Baseline Mean Squared Error: {baseline_mse}')\n",
    "print(f'Linear Regression Mean Squared Error: {mse_og}')\n",
    "print(f'Lasso Regression Mean Squared Error: {mse_l1}')\n",
    "print(f'Ridge Regression Mean Squared Error: {mse_l2}')\n",
    "print(f'ElasticNet Regression Mean Squared Error: {mse_elastic}')\n",
    "\n",
    "# Calculate improvements over baseline\n",
    "improvements = {\n",
    "    'Linear Regression': baseline_mse - mse_og,\n",
    "    'Lasso Regression': baseline_mse - mse_l1,\n",
    "    'Ridge Regression': baseline_mse - mse_l2,\n",
    "    'ElasticNet Regression': baseline_mse - mse_elastic,\n",
    "    'Random Forest Regression': baseline_mse - mse_smogn\n",
    "}\n",
    "\n",
    "# Print improvements\n",
    "print('\\nMSE Improvement Over Baseline:')\n",
    "for model, improvement in improvements.items():\n",
    "    print(f'{model} improvement: {improvement}')\n",
    "\n",
    "# Select the best model\n",
    "best_model = max(improvements, key=improvements.get)\n",
    "best_improvement = improvements[best_model]\n",
    "print(f'\\nBest Model: {best_model} with improvement: {best_improvement}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6326b77b-11b3-4bb7-8b7b-220d45d461b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "mse_smogn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8d9c197-1e22-409d-aaa5-c2908af92abc",
   "metadata": {},
   "outputs": [],
   "source": [
    "mae = mean_absolute_error(y_test, y_pred)\n",
    "r2 = r2_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cdcd92e-e25e-4cb4-94ea-7993e9ff50a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "mae"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ec13b30-edc3-45db-8d3d-2275e19c7871",
   "metadata": {},
   "outputs": [],
   "source": [
    "r2"
   ]
  },
  {
   "cell_type": "raw",
   "id": "0a35e778-d64e-42af-8f19-936417b1678c",
   "metadata": {},
   "source": [
    "# Combine features and target into a single DataFrame for SMOGN\n",
    "df_combined = X.copy()\n",
    "df_combined['average_rating'] = y\n",
    "\n",
    "# Apply SMOGN\n",
    "smogned_data = smogn.smoter(\n",
    "    data = df_combined,       \n",
    "    # DataFrame\n",
    "    y = 'average_rating'                \n",
    "    # Target variable name\n",
    ")\n",
    "\n",
    "# Separate features and target again\n",
    "X_resampled = smogned_data.drop(columns=['average_rating'])\n",
    "y_resampled = smogned_data['average_rating']\n",
    "\n",
    "# Split the data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_resampled, y_resampled, test_size=0.2, random_state=42)\n",
    "\n"
   ]
  },
  {
   "cell_type": "raw",
   "id": "2bde28ee-a0ab-49d8-b4c0-b22c97335960",
   "metadata": {},
   "source": [
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_resampled, y_resampled, test_size=0.2, random_state=42)\n",
    "\n",
    "# Baseline model (mean model)\n",
    "dummy = DummyRegressor(strategy=\"mean\")\n",
    "dummy.fit(X_train, y_train)\n",
    "y_dummy_pred = dummy.predict(X_test)\n",
    "baseline_mse = mean_squared_error(y_test, y_dummy_pred)\n",
    "print(f'Baseline Mean Squared Error: {baseline_mse}')\n",
    "\n",
    "# Linear Regression\n",
    "lr_model = LinearRegression()\n",
    "lr_model.fit(X_train, y_train)\n",
    "y_lr_pred = lr_model.predict(X_test)\n",
    "mse_og = mean_squared_error(y_test, y_lr_pred)\n",
    "print(f'Linear Regression Mean Squared Error: {mse_og}')\n",
    "\n",
    "# Lasso Regression\n",
    "lasso_model = Lasso(alpha=0.1)\n",
    "lasso_model.fit(X_train, y_train)\n",
    "y_lasso_pred = lasso_model.predict(X_test)\n",
    "mse_l1 = mean_squared_error(y_test, y_lasso_pred)\n",
    "print(f'Lasso Regression Mean Squared Error: {mse_l1}')\n",
    "\n",
    "# Ridge Regression\n",
    "ridge_model = Ridge(alpha=0.1)\n",
    "ridge_model.fit(X_train, y_train)\n",
    "y_ridge_pred = ridge_model.predict(X_test)\n",
    "mse_l2 = mean_squared_error(y_test, y_ridge_pred)\n",
    "print(f'Ridge Regression Mean Squared Error: {mse_l2}')\n",
    "\n",
    "# ElasticNet Regression\n",
    "elastic_net_model = ElasticNet(alpha=0.1, l1_ratio=0.5)\n",
    "elastic_net_model.fit(X_train, y_train)\n",
    "y_elastic_net_pred = elastic_net_model.predict(X_test)\n",
    "mse_elastic = mean_squared_error(y_test, y_elastic_net_pred)\n",
    "print(f'ElasticNet Regression Mean Squared Error: {mse_elastic}')\n",
    "\n",
    "# Random Forest Regression\n",
    "rf_model = RandomForestRegressor()\n",
    "rf_model.fit(X_train, y_train)\n",
    "y_rf_pred = rf_model.predict(X_test)\n",
    "mse_rf = mean_squared_error(y_test, y_rf_pred)\n",
    "print(f'Random Forest Mean Squared Error: {mse_rf}')\n",
    "\n",
    "# Calculate improvements over baseline\n",
    "improvements = {\n",
    "    'Linear Regression': baseline_mse - mse_og,\n",
    "    'Lasso Regression': baseline_mse - mse_l1,\n",
    "    'Ridge Regression': baseline_mse - mse_l2,\n",
    "    'ElasticNet Regression': baseline_mse - mse_elastic,\n",
    "    'Random Forest Regression': baseline_mse - mse_rf\n",
    "}\n",
    "\n",
    "# Print improvements\n",
    "print('\\nMSE Improvement Over Baseline:')\n",
    "for model, improvement in improvements.items():\n",
    "    print(f'{model} improvement: {improvement}')\n",
    "\n",
    "# Select the best model\n",
    "best_model = max(improvements, key=improvements.get)\n",
    "best_improvement = improvements[best_model]\n",
    "print(f'\\nBest Model: {best_model} with improvement: {best_improvement}')\n",
    "\n",
    "# Additional evaluation metrics for the best model\n",
    "if best_model == 'Linear Regression':\n",
    "    y_best_pred = y_lr_pred\n",
    "elif best_model == 'Lasso Regression':\n",
    "    y_best_pred = y_lasso_pred\n",
    "elif best_model == 'Ridge Regression':\n",
    "    y_best_pred = y_ridge_pred\n",
    "elif best_model == 'ElasticNet Regression':\n",
    "    y_best_pred = y_elastic_net_pred\n",
    "elif best_model == 'Random Forest Regression':\n",
    "    y_best_pred = y_rf_pred\n",
    "\n",
    "# Calculate and print additional metrics\n",
    "mae = mean_absolute_error(y_test, y_best_pred)\n",
    "r2 = r2_score(y_test, y_best_pred)\n",
    "print(f'\\nMean Absolute Error for {best_model}: {mae}')\n",
    "print(f'R-squared for {best_model}: {r2}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95fb2b28-3abb-4f2f-a349-250ea43c98f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "mae"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "319c0e02-add3-40b0-b447-6b4a650978c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "r2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58027830-6d1a-4558-924b-a50c4b2030e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.ndim, X_test.ndim, y_train.ndim, y_test.ndim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a3d4d23-80d7-4e39-b81e-321565478ba0",
   "metadata": {},
   "outputs": [],
   "source": [
    "reg = LazyRegressor(verbose=0, ignore_warnings=False, custom_metric=None)\n",
    "models, predictions = reg.fit(X_train, X_test, y_train, y_test)\n",
    "\n",
    "models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ac491df-77d5-47e1-adb0-de03e20b82f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_rf = RandomForestRegressor(n_estimators=100, random_state=42)\n",
    "best_rf.fit(X_train, y_train)\n",
    "\n",
    "# Get feature importances\n",
    "importance = best_rf.feature_importances_\n",
    "feature_names = X.columns\n",
    "\n",
    "# Plot feature importances\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.barh(feature_names, importance)\n",
    "plt.xlabel('Feature Importance')\n",
    "plt.ylabel('Features')\n",
    "plt.title('Feature Importance in Random Forest')\n",
    "plt.show()\n",
    "\n",
    "# Train a Random Forest Regressor\n",
    "model_smogn = RandomForestRegressor()\n",
    "model_smogn.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions\n",
    "y_pred = model_smogn.predict(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "mse_smogn = mean_squared_error(y_test, y_pred)\n",
    "print(f'Mean Squared Error model smogn: {mse_smogn}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05d0672e-3de6-45d9-af3e-1725feb76d34",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate and print additional metrics\n",
    "mae = mean_absolute_error(y_test, y_pred)\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "rmse_smogn = np.sqrt(mse_smogn)\n",
    "print(f'\\nMean Absolute Error (MAE): {mae}')\n",
    "print(f'R-squared: {r2}')\n",
    "print(f'Root Mean Squared Error (RMSE):{rmse_smogn}')\n",
    "print(f'Mean Squared Error (MSE): {mse_smogn}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "200e3358-37b4-4e46-af1d-e222c9f860e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "comparison= pd.DataFrame({'Actual': y_test, 'Predicted': y_pred, 'Residual': y_test - y_pred})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2bbb307-0a22-415a-9383-b5b4f75ffdce",
   "metadata": {},
   "outputs": [],
   "source": [
    "comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d3def06-86d6-4a75-ac29-0dff0bd7184b",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(19, 10))\n",
    "sns.regplot(x=y_pred, y=y_test, marker=\"+\", line_kws={'color':'darkred','alpha':1.0})\n",
    "plt.xlabel('Predicted Values')\n",
    "plt.ylabel('True Values')\n",
    "plt.title('Regression Plot of Predicted vs True Values')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "391c7d38-8b6f-453e-9384-3a11184d9847",
   "metadata": {},
   "source": [
    "LGBMRegressor model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a7cf9b5-a269-48c7-ab9c-ca5d2fbb6ce8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separate features and target\n",
    "X2 = df.drop(columns=['average_rating'])\n",
    "y2 = df['average_rating']\n",
    "\n",
    "# Identify features to normalize\n",
    "features_to_normalize = ['ratings_count', 'text_reviews_count']\n",
    "\n",
    "# Initialize the scaler\n",
    "scaler = StandardScaler()\n",
    "\n",
    "# Fit and transform the specific features\n",
    "X2[features_to_normalize] = scaler.fit_transform(X[features_to_normalize])\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train2, X_test2, y_train2, y_test2 = train_test_split(X2, y2, test_size=0.2, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06a83d65-fe51-41b5-a771-fd129e987721",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get feature importances\n",
    "importance = best_rf.feature_importances_\n",
    "feature_names = X.columns\n",
    "\n",
    "# Plot feature importances\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.barh(feature_names, importance)\n",
    "plt.xlabel('Feature Importance')\n",
    "plt.ylabel('Features')\n",
    "plt.title('Feature Importance in LGBMRegressor')\n",
    "plt.show()\n",
    "\n",
    "# Train a Random Forest Regressor\n",
    "model_smogn = LGBMRegressor()\n",
    "model_smogn.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions\n",
    "y_pred2 = model_smogn.predict(X_test)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14f7c462-e851-49f3-9bdd-8cd1baab84ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate and print additional metrics\n",
    "mae = mean_absolute_error(y_test, y_pred)\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "rmse_smogn = np.sqrt(mse_smogn)\n",
    "print(f'\\nMean Absolute Error (MAE): {mae}')\n",
    "print(f'R-squared: {r2}')\n",
    "print(f'Root Mean Squared Error (RMSE):{rmse_smogn}')\n",
    "print(f'Mean Squared Error (MSE): {mse_smogn}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7319b9e2-e141-428d-a729-fd6426bd57e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "comparison= pd.DataFrame({'Actual': y_test2, 'Predicted': y_pred2, 'Residual': y_test2 - y_pred2})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bc20e90-d63a-4277-9ffd-7842dcd08b09",
   "metadata": {},
   "outputs": [],
   "source": [
    "comparison.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6607b80-6d6a-4263-a8e3-965bafd13807",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(5, 5))\n",
    "viz = PredictionError(model_smogn)\n",
    "viz.fit(X_train, y_train)\n",
    "viz.score(X_test, y_test)\n",
    "viz.show();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45ca9b8a-7fc7-4dab-9ae6-ca26120db858",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(19, 10))\n",
    "sns.regplot(x=y_pred2, y=y_test2, marker=\"+\", line_kws={'color':'darkred','alpha':1.0})\n",
    "plt.xlabel('Predicted Values')\n",
    "plt.ylabel('True Values')\n",
    "plt.title('Regression Plot of Predicted vs True Values')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76ac2903-37bc-4739-9393-3f399c40a69d",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = GradientBoostingRegressor()\n",
    "\n",
    "parameters = {\n",
    "    'learning_rate': [0.001, 0.01, 0.02, 0.1, 0.2, 1.0],\n",
    "    'n_estimators': [10, 50, 100, 200]\n",
    "}\n",
    "\n",
    "grad_Gra = GridSearchCV(model, parameters, refit=True)\n",
    "grad_Gra.fit(X_train, y_train)\n",
    "\n",
    "print('Best Score: ', grad_Gra.best_score_*100, '\\nBest Parameters: ', grad_Gra.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b400c7e-3606-44bb-9f25-a8f412c0f11e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Refit the model on the entire training dataset using the best parameters\n",
    "best_model = GradientBoostingRegressor(learning_rate=grad_Gra.best_params_['learning_rate'],\n",
    "                                       n_estimators=grad_Gra.best_params_['n_estimators'],\n",
    "                                       max_depth=4)  # Assuming max_depth was part of the grid search\n",
    "best_model.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on the test set\n",
    "y_pred = best_model.predict(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "rmse = np.sqrt(mse)\n",
    "mae = mean_absolute_error(y_test, y_pred)\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "print(f'Mean Squared Error (MSE): {mse}')\n",
    "print(f'Root Mean Squared Error (RMSE): {rmse}')\n",
    "print(f'Mean Absolute Error (MAE): {mae}')\n",
    "print(f'R^2 Score: {r2}')\n",
    "\n",
    "# Feature importance\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "feature_importances = best_model.feature_importances_\n",
    "features = X_train.columns\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.barh(features, feature_importances)\n",
    "plt.xlabel('Feature Importance')\n",
    "plt.ylabel('Features')\n",
    "plt.title('Feature Importance in Gradient Boosting Regressor')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a2507c2-1d78-4552-807f-907777f07782",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the models\n",
    "models = {\n",
    "    'ExtraTreesRegressor': ExtraTreesRegressor(),\n",
    "    'RandomForestRegressor': RandomForestRegressor(),\n",
    "    'BaggingRegressor': BaggingRegressor(estimator=RandomForestRegressor(), n_estimators=10),\n",
    "    'LGBMRegressor': LGBMRegressor()\n",
    "}\n",
    "\n",
    "# Train and evaluate each model\n",
    "for name, model in models.items():\n",
    "    print(f'\\n{name}')\n",
    "    model.fit(X_train, y_train)\n",
    "    y_pred = model.predict(X_test)\n",
    "    \n",
    "    # Calculate metrics\n",
    "    mse = mean_squared_error(y_test, y_pred)\n",
    "    rmse = np.sqrt(mse)\n",
    "    mae = mean_absolute_error(y_test, y_pred)\n",
    "    r2 = r2_score(y_test, y_pred)\n",
    "    \n",
    "    print(f'Mean Squared Error (MSE): {mse}')\n",
    "    print(f'Root Mean Squared Error (RMSE): {rmse}')\n",
    "    print(f'Mean Absolute Error (MAE): {mae}')\n",
    "    print(f'R^2 Score: {r2}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0039a642-c969-43ed-83e1-52b69c680280",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train, evaluate, and visualize each model\n",
    "for name, model in models.items():\n",
    "    print(f'\\n{name}')\n",
    "    model.fit(X_train, y_train)\n",
    "    y_pred = model.predict(X_test)\n",
    "    \n",
    "    # Calculate metrics\n",
    "    mse = mean_squared_error(y_test, y_pred)\n",
    "    rmse = np.sqrt(mse)\n",
    "    mae = mean_absolute_error(y_test, y_pred)\n",
    "    r2 = r2_score(y_test, y_pred)\n",
    "    \n",
    "    print(f'Mean Squared Error (MSE): {mse}')\n",
    "    print(f'Root Mean Squared Error (RMSE): {rmse}')\n",
    "    print(f'Mean Absolute Error (MAE): {mae}')\n",
    "    print(f'R^2 Score: {r2}')\n",
    "    \n",
    "    # Visualize prediction error\n",
    "    fig = plt.figure(figsize=(5, 5))\n",
    "    viz = PredictionError(model)\n",
    "    viz.fit(X_train, y_train)\n",
    "    viz.score(X_test, y_test)\n",
    "    viz.show()\n",
    "\n",
    "\n",
    "    # Plot feature importance if available\n",
    "    if hasattr(model, 'feature_importances_'):\n",
    "        feature_importances = model.feature_importances_\n",
    "        features = X_train.columns\n",
    "\n",
    "        plt.figure(figsize=(10, 6))\n",
    "        plt.barh(features, feature_importances)\n",
    "        plt.xlabel('Feature Importance')\n",
    "        plt.ylabel('Features')\n",
    "        plt.title(f'Feature Importance in {name}')\n",
    "        plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a8904a4-d52d-431b-bbb4-dd677f7a51d5",
   "metadata": {},
   "outputs": [],
   "source": [
    " "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
