import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
import missingno as ms


df = pd.read_csv("books.csv",sep=",") #,index_col="bookID"


# Replace 'your_detected_encoding' with the actual encoding detected, e.g., 'utf-8'
df = pd.read_csv('books.csv', index_col="bookID", encoding='utf-8')

# Print the DataFrame to verify that the text is readabl
df.head()


df.isnull().values.any()


type(df)


df.head(10)


df.shape


df.info()





df.ndim


df.describe()


df.columns[:]


df.loc[16914]


#df['authors'].replace("David E. Smith (Turgon of TheOneRing.net","David E. Smith",inplace=True)


df.loc[16914]


df['average_rating'].replace(" one of the founding members of this Tolkien website)/Verlyn Flieger/Turgon (=David E. Smith)",np.nan,inplace=True)
df['authors'].replace("David E. Smith (Turgon of TheOneRing.net","David E. Smith",inplace=True)


df.loc[16914]


df.info()


#concatonate authors from col. authors and average_rating
combined_value1 = df.loc[12224,'authors']+df.loc[12224,'average_rating']
df.loc[12224,'authors'] = combined_value1


df.loc[16914]


#combined_value2 = df.loc[16914,'authors']+df.loc[16914,'average_rating']
#df.loc[16914,'authors'] = combined_value2
combined_value3 = str(df.loc[22128,'authors'])+","+str(df.loc[22128,'average_rating'])
df.loc[22128,'authors'] = combined_value3


combined_value4 = str(df.loc[34889,'authors'])+str(df.loc[34889,'average_rating'])
df.loc[34889,'authors'] = combined_value4


#replace the unfinished author list with the concatonated values aboved
df.loc[12224,'authors'] = combined_value1
#df.loc[16914,'authors'] = combined_value2
df.loc[22128,'authors'] = combined_value3
df.loc[34889,'authors'] = combined_value4


#readjust misaligned columns values by shifting all columns to the left
df.loc[12224,'average_rating'] = df.loc[12224,'isbn']
df.loc[12224,'isbn'] = df.loc[12224,'isbn13']
df.loc[12224,'isbn13'] = df.loc[12224,'language_code']
df.loc[12224,'language_code'] = df.loc[12224,'num_pages']
df.loc[12224,'num_pages'] = df.loc[12224,'ratings_count']
df.loc[12224,'ratings_count'] = df.loc[12224,'text_reviews_count']
df.loc[12224,'text_reviews_count'] = df.loc[12224,'publication_date']
df.loc[12224,'publication_date'] = df.loc[12224,'publisher']
df.loc[12224,'publisher'] = df.loc[12224,'unnamed']

df.loc[16914,'average_rating'] = df.loc[16914,'isbn']
df.loc[16914,'isbn'] = df.loc[16914,'isbn13']
df.loc[16914,'isbn13'] = df.loc[16914,'language_code']
df.loc[16914,'language_code'] = df.loc[16914,'num_pages']
df.loc[16914,'num_pages'] = df.loc[16914,'ratings_count']
df.loc[16914,'ratings_count'] = df.loc[16914,'text_reviews_count']
df.loc[16914,'text_reviews_count'] = df.loc[16914,'publication_date']
df.loc[16914,'publication_date'] = df.loc[16914,'publisher']
df.loc[16914,'publisher'] = df.loc[16914,'unnamed']

df.loc[22128,'average_rating'] = df.loc[22128,'isbn']
df.loc[22128,'isbn'] = df.loc[22128,'isbn13']
df.loc[22128,'isbn13'] = df.loc[22128,'language_code']
df.loc[22128,'language_code'] = df.loc[22128,'num_pages']
df.loc[22128,'num_pages'] = df.loc[22128,'ratings_count']
df.loc[22128,'ratings_count'] = df.loc[22128,'text_reviews_count']
df.loc[22128,'text_reviews_count'] = df.loc[22128,'publication_date']
df.loc[22128,'publication_date'] = df.loc[22128,'publisher']
df.loc[22128,'publisher'] = df.loc[22128,'unnamed']

df.loc[34889,'average_rating'] = df.loc[34889,'isbn']
df.loc[34889,'isbn'] = df.loc[34889,'isbn13']
df.loc[34889,'isbn13'] = df.loc[34889,'language_code']
df.loc[34889,'language_code'] = df.loc[34889,'num_pages']
df.loc[34889,'num_pages'] = df.loc[34889,'ratings_count']
df.loc[34889,'ratings_count'] = df.loc[34889,'text_reviews_count']
df.loc[34889,'text_reviews_count'] = df.loc[34889,'publication_date']
df.loc[34889,'publication_date'] = df.loc[34889,'publisher']
df.loc[34889,'publisher'] = df.loc[34889,'unnamed']


df.loc[12224]


df.loc[22128]


df.loc[34889]


df.loc[16914]


df.drop(columns='unnamed',axis=1,inplace=True)


df.info()


df.isna().sum()


ms.bar(df);


df.info()


#value = df.loc[12224]['text_reviews_count']
# Simplified function to convert string numbers to integers, non-numeric to 0
def convert_to_int(str_values):
    try:
        return int(str_values)
    except ValueError:
        return 0

# Apply the conversion function to the entire 'text_reviews_count' column
df['text_reviews_count'] = df['text_reviews_count'].apply(convert_to_int)

# Print the DataFrame after conversion
print("\nDataFrame after conversion:")
type(df.loc[12224]['text_reviews_count'])


df.loc[12224]


df['num_pages'] = df['num_pages'].astype(int)


# Detect rows where 'num_pages' cannot be converted to a numeric value
non_numeric_rows = df[pd.to_numeric(df['num_pages'], errors='coerce').isna()]

# Print the rows with non-numeric 'num_pages' values
print("Rows with non-numeric 'num_pages' values:")
print(non_numeric_rows)


df.isna().sum()


df['language_code'].value_counts()


df['language_code'].to_csv("language_code.csv")





df.language_code.replace(["eng","en-US","en-GB"],"eng", inplace=True)


#df.language_code.replace(["ara","nl","srp","msa","glg","wel","nor","tur","gla","ale","mul","zho","grc","por","en-CA","ita","enm","lat","rus","swe","jpn","ger"],"others", inplace=True)


df.language_code.replace(["ara","nl","srp","msa","glg","wel","nor","tur","gla","ale","mul","zho","grc","por","en-CA","ita","enm","lat","rus","swe","jpn","ger","fre","spa"],"others", inplace=True)


df['language_code'].value_counts()


df = df.drop(columns=['isbn','isbn13'])


df.head(10)


df['publisher'].value_counts()


# Find all unique types in the 'num_pages' column
unique_types = df['average_rating'].apply(type).unique()

# Print the unique types
print("Unique types in 'average_rating' column:")
for t in unique_types:
    print(t)


df.iloc[3340:3350]


df.iloc[5877]


# Convert 'average_rating' to numeric
df['average_rating'] = pd.to_numeric(df['average_rating'])

type(df.loc[2]['average_rating'])




# Find all unique types in the 'num_pages' column
unique_types = df['average_rating'].apply(type).unique()

# Print the unique types
print("Unique types in 'average_rating' column:")
for t in unique_types:
    print(t)

# Group by publisher and calculate the average rating
publisher_ratings = df.groupby('publisher')['average_rating'].mean().reset_index()

# Sort publishers by average rating in descending order
publisher_ratings = publisher_ratings.sort_values(by='average_rating', ascending=False)

# Print the top publishers by average rating
print(publisher_ratings.head(10))


import pandas as pd

# Assuming 'df' is your DataFrame

# Convert 'average_rating' column to float
df['average_rating'] = df['average_rating'].astype(float)

# Verify the conversion by finding all unique types in the 'average_rating' column
unique_types = df['average_rating'].apply(type).unique()

# Print the unique types
print("Unique types in 'average_rating' column:")
for t in unique_types:
    print(t)

# Group by publisher and calculate the average rating
publisher_ratings = df.groupby('publisher')['average_rating'].mean().reset_index()

# Sort publishers by average rating in descending order
publisher_ratings = publisher_ratings.sort_values(by='average_rating', ascending=False)

# Print the top publishers by average rating
print(publisher_ratings.head(10))



# import chardet

# # Detect the encoding of a file
# with open('/Users/tanattiya/Desktop/DSTI/ML/Project1/books.csv', 'rb') as f:
#     result = chardet.detect(f.read())

# print(result)



#print(df[df['bookID'] == 22802])
df.iloc[6076:6090]


print(df.columns)



df.loc[22802:22810]


#far left's indexing starts from 0
df.iloc[1]


#position of the index of the column set as index_col (this case = bookID)
df.loc[1]


type(df.loc[2]['average_rating'])






# # Calculate the average rating for each publisher
# publisher_ratings = df.groupby('publisher')['average_rating'].mean().reset_index()

# # Sort publishers by average rating in descending order and select the top 50
# top_publishers = publisher_ratings.sort_values(by='average_rating', ascending=False).head(50)

# # Plot the average ratings by publisher for the top 50
# plt.figure(figsize=(10, 8))
# sns.barplot(x='average_rating', y='publisher', data=top_publishers)
# plt.title('Average Book Rating by Publisher (Top 50)')
# plt.xlabel('Average Rating')
# plt.ylabel('Publisher')
# plt.show()

# # Filter the original DataFrame to include only the top 50 publishers
# df_filtered = df[df['publisher'].isin(top_publishers['publisher'])]

# # Perform ANOVA test to see if the differences in ratings are statistically significant
# grouped_ratings = [group['average_rating'].values for name, group in df_filtered.groupby('publisher')]
# anova_result = f_oneway(*grouped_ratings)

# print(f"ANOVA test result: F={anova_result.statistic}, p={anova_result.pvalue}")


numerical_features = df.select_dtypes(exclude=["object"])


numerical_features


numerical_features.info()


df.head(50)


df.info()


sns.heatmap(numerical_features.corr(),annot=True,center=True);


for feature in numerical_features:
    plt.figure(figsize=(8,5))
    sns.boxplot(x=numerical_features[feature]);


for feature in numerical_features:
    plt.figure(figsize=(8,5))
    sns.distplot(numerical_features[feature],bins=5);


target = numerical_features["average_rating"]


for feature in numerical_features:
    plt.figure(figsize=(8,5))
    sns.regplot(x=numerical_features[feature],y=target,data=numerical_features);


df.language_code.value_counts().plot.bar();
#(autopct="%.1f%%",shadow=True,legend=True,figsize=(15,8));


#df.publisher.value_counts().plot.bar(figsize=(20,6));


# # Let's look at the top 10 rated books
# top10Books = df.nlargest(10, ['ratings_count']).set_index('title')['ratings_count']
# plot_dims = (12, 8)
# fig, ax = plt.subplots(figsize=plot_dims)
# sns.barplot(top10Books, top10Books.index)

# for i in ax.patches:
#     ax.text(i.get_width()+.3, i.get_y()+0.5, str(round(i.get_width())), fontsize = 15, color = 'k')
    
# plt.show()


df.query("authors=='Bill Bryson'")

# Select the top 10 books using query function in combination with 
top_10_books = df.nlargest(10, 'average_rating').query('index >= 0')

top_10_books


df[["title","average_rating"]].query("average_rating==5.0")


for i in df.columns:
    print(i,df[i].duplicated().sum())


df.nunique()


775+10352


df[df.authors=="Don DeLillo"].count()


df.duplicated().sum()


df_time_series = numerical_features.copy()
df_time_series.head()


df_time_series["date"]=df["publication_date"]
df_time_series.head()


df_time_series.info()


# If you know the format of your dates, specify it
# Example format: 'dd/mm/yyyy' or 'yyyy-mm-dd'
date_format = '%m/%d/%Y'  # Adjust this format to your needs
df_time_series["date"] = pd.to_datetime(df_time_series["date"], format=date_format, errors='coerce')


df_time_series.info()


df_time_series["date"].isna().sum()


4555+6572


df_time_series.info()


df_time_series.head()


df_time_series.set_index(df_time_series["date"],inplace=True)
df_time_series.sort_index(inplace=True)


df_time_series.head()


df_time_series.drop("date",axis=1,inplace=True)
df_time_series.head()


df_time_series["average_rating"].resample('M').mean().plot();


df_time_series["average_rating"].resample('2W').std().plot();


df_time_series["num_pages"].resample('M').mean().plot();


df_time_series["ratings_count"].resample('Y').mean().plot();


df_time_series["average_rating"].resample('W').agg(["mean","std","median"]).plot();


df_time_series["text_reviews_count"].resample('Y').agg(["mean","std","median"]).plot();


from yellowbrick.cluster import KElbowVisualizer, SilhouetteVisualizer, silhouette_visualizer
from sklearn.cluster import KMeans


kms=KMeans(random_state=42,n_init='auto')
viz=KElbowVisualizer(kms,k=(1,20))
viz.fit(numerical_features)
viz.show();


model=KMeans(n_clusters=3,random_state=42)
y_prediction=model.fit_predict(numerical_features)


y_prediction


sns.histplot(x=y_prediction);


numerical_features["clusters"]=y_prediction
numerical_features.head()


numerical_features["clusters"].value_counts().plot.bar().legend();


df0=numerical_features[numerical_features.clusters==0]
df1=numerical_features[numerical_features.clusters==1]
df2=numerical_features[numerical_features.clusters==2]


plt.scatter(df0.num_pages,df0.average_rating,color="red",label="cluster 0")
plt.scatter(df1.num_pages,df1.average_rating,color="orange",label="cluster 1")
plt.scatter(df2.num_pages,df2.average_rating,color="yellow",label="cluster 2")
plt.scatter(model.cluster_centers_[:,1],model.cluster_centers_[:,0],s=100,marker="*",label="centroids",color="black")
plt.xlabel("number of pages")
plt.ylabel("average rating")
plt.legend()
plt.show()


plt.scatter(df0.ratings_count,df0.average_rating,color="red",label="cluster 0")
plt.scatter(df1.ratings_count,df1.average_rating,color="orange",label="cluster 1")
plt.scatter(df2.ratings_count,df2.average_rating,color="yellow",label="cluster 2")
plt.scatter(model.cluster_centers_[:,2],model.cluster_centers_[:,0],s=100,marker="*",label="centroids",color="black")
plt.xlabel("ratings count")
plt.ylabel("average rating")
plt.legend()
plt.show()


plt.scatter(df0.text_reviews_count,df0.average_rating,color="red",label="cluster 0")
plt.scatter(df1.text_reviews_count,df1.average_rating,color="orange",label="cluster 1")
plt.scatter(df2.text_reviews_count,df2.average_rating,color="yellow",label="cluster 2")
plt.scatter(model.cluster_centers_[:,3],model.cluster_centers_[:,0],s=100,marker="*",label="centroids",color="black")
plt.xlabel("text reviews count")
plt.ylabel("average rating")
plt.legend()
plt.show()


X=numerical_features.drop("clusters",axis=1)
#silhouette_visualizer(model, df_silhouette, colors='yellowbrick')


from yellowbrick.cluster import SilhouetteVisualizer, silhouette_visualizer
from sklearn.cluster import KMeans


vz = SilhouetteVisualizer(model,colors='yellowbrick')
vz.fit(X)
vz.show();


df.head(10)


future_data=df.copy()


from sklearn.model_selection import train_test_split
from sklearn.preprocessing import LabelEncoder, MinMaxScaler, StandardScaler, RobustScaler, PolynomialFeatures


df.info()


df.language_code.value_counts()


df_language_code=pd.get_dummies(df["language_code"],dtype=int)
df_language_code



# Step 1: Split the DataFrame into two halves
mid_index = len(df) // 2
train_half = df.iloc[:mid_index].copy()
test_half = df.iloc[mid_index:].copy()

# Step 2: Add a label to distinguish between train and test data
train_half["Label"] = "train"
test_half["Label"] = "test"

# Step 3: Combine the two halves into one DataFrame
combined_data = pd.concat([train_half, test_half], axis=0)




combined_df = df.copy()


combined_df.drop(["title","authors","publisher"],axis=1,inplace=True)
combined_data.drop(["title","authors","publisher"],axis=1,inplace=True)


#BAS
#use df to FE by 1. publication -> datetimetype -> pub_year


date_format = '%m/%d/%Y'  # Adjust this format to your needs
combined_data['publication_date'] = pd.to_datetime(combined_data['publication_date'], format=date_format, errors='coerce')
combined_data['publication_year'] = combined_data['publication_date'].dt.year


#BAS
#use df to FE by 1. publication -> datetimetype -> pub_year


date_format = '%m/%d/%Y'  # Adjust this format to your needs
combined_df['publication_date'] = pd.to_datetime(combined_df['publication_date'], format=date_format, errors='coerce')
combined_df['publication_year'] = combined_df['publication_date'].dt.year


print(combined_df['publication_year'].dtype)



combined_df.head()


combined_df.drop("publication_date",axis=1,inplace=True)
combined_data.drop("publication_date",axis=1,inplace=True)


# Assuming df_combined is your DataFrame
# First, coerce errors to NaT to identify problematic entries
# Check for NaT values to identify problematic entries
problematic_rows = combined_data[combined_data["publication_year"].isna()]

# Inspect problematic rows to understand the issue
problematic_rows

# Further troubleshoot and correct the data as necessary
# Calculate the mean of the publication_year column, excluding any zeros
mean_publication_year = combined_data['publication_year'][combined_data['publication_year'] != 0].mean()

# Fill missing values and zeros in the publication_year column with the mean
combined_data['publication_year'].replace(0, np.nan, inplace=True)
combined_data['publication_year'].fillna(mean_publication_year, inplace=True)

# Verify the changes
print(combined_data['publication_year'].head(10))



# Assuming df_combined is your DataFrame
# First, coerce errors to NaT to identify problematic entries
# Check for NaT values to identify problematic entries
problematic_rows = combined_df[combined_df["publication_year"].isna()]

# Inspect problematic rows to understand the issue
problematic_rows

# Further troubleshoot and correct the data as necessary
# Calculate the mean of the publication_year column, excluding any zeros
mean_publication_year = combined_df['publication_year'][combined_df['publication_year'] != 0].mean()

# Fill missing values and zeros in the publication_year column with the mean
combined_df['publication_year'].replace(0, np.nan, inplace=True)
combined_df['publication_year'].fillna(mean_publication_year, inplace=True)

# Verify the changes
print(combined_df['publication_year'].head(10))




problematic_rows = combined_df[combined_df["publication_year"].isna()]

# Inspect problematic rows to understand the issue
problematic_rows





combined_df.head()



# Extract numerical, discrete, continuous, and categorical features
numerical_features = [col for col in combined_df.columns if combined_df[col].dtype != 'O']
discrete_features = [col for col in numerical_features if len(combined_df[col].unique()) < 25 and col not in ['bookID']]
continuous_features = [feature for feature in numerical_features if feature not in discrete_features + ['bookID']]
categorical_features = [col for col in combined_df.columns if combined_df[col].dtype == 'O']

# Print the results
print("Total Number of Numerical Columns: ", len(numerical_features))
print("Number of Discrete Features: ", len(discrete_features))
print("Number of Continuous Features: ", len(continuous_features))
print("Number of Categorical Features: ", len(categorical_features))



combined_df.head()


set(combined_df.language_code)





f, axes = plt.subplots(4,2 , figsize=(30, 15), sharex=False)
for i, feature in enumerate(continuous_features):
    sns.histplot(data=combined_data, x = feature, hue="Label",ax=axes[i%4, i//4]) 



f, axes = plt.subplots(5,3 , figsize=(30, 30), sharex=False)
for i, feature in enumerate(numerical_features):
    sns.scatterplot(data=combined_data, x = feature, y= "average_rating",ax=axes[i%7, i//7])











combined_df.publication_year.nsmallest(10)








combined_df.head()





categorical_features


combined_df.info()





continuous_features


combined_df.info()


data_language_code=pd.get_dummies(combined_df["language_code"],dtype=int)
data_language_code


combined_df=pd.concat([combined_df,data_language_code],axis=1)
combined_df.drop(["language_code"],axis=1, inplace=True)


combined_df.info()


combined_df.head()


combined_df.info()


# Identifying rows with negative values in specified columns
negative_values_df = combined_df[
    (combined_df['num_pages'] < 0) |
    (combined_df['ratings_count'] < 0) |
    (combined_df['text_reviews_count'] < 0) |
    (combined_df['publication_year'] < 0)
]

# Display the rows with negative values
negative_values_df




# List of columns to clip
columns_to_clip = ["text_reviews_count", "ratings_count","publication_year"]

# Clipping the specified columns
for col in columns_to_clip:
    combined_df[col].clip(lower=combined_df[col].quantile(0.20), upper=combined_df[col].quantile(0.80), inplace=True)

# Plotting boxplots before clipping
for col in columns_to_clip:
    sns.boxplot(x=combined_df[col])
    plt.title(f'Boxplot of {col} (Before Clipping)')
    plt.show()

# Copy the processed data
data_wo_outliers = combined_df.copy()

# Plotting boxplots after clipping
for col in columns_to_clip:
    sns.boxplot(x=data_wo_outliers[col])
    plt.title(f'Boxplot of {col} (After Clipping)')
    plt.show()



combined_df.info()


X=combined_df.drop("average_rating",axis=1)
y=combined_df.average_rating


X


y


X.ndim


y.ndim


combined_df.describe()


from yellowbrick.model_selection import FeatureImportances
from sklearn.linear_model import LinearRegression, SGDRegressor
from sklearn.neighbors import KNeighborsRegressor
from sklearn.tree import DecisionTreeRegressor
from sklearn.ensemble import GradientBoostingRegressor


modelbas1 = GradientBoostingRegressor()
viz = FeatureImportances(modelbas1)
viz.fit(X, y)
viz.show();


modelbas1 = LinearRegression()
viz = FeatureImportances(modelbas1)
viz.fit(X, y)
viz.show();


modelbas1 = SGDRegressor()
viz = FeatureImportances(modelbas1)
viz.fit(X, y)
viz.show();


modelbas1 = DecisionTreeRegressor()
viz = FeatureImportances(modelbas1)
viz.fit(X, y)
viz.show();


combined_df.isna().sum()


# !pip install lazypredict


# !pip install --upgrade scikit-learn


from lazypredict.Supervised import LazyRegressor


X=combined_df.drop("average_rating",axis=1)
y=combined_df.average_rating


X_train_bas, X_test_bas, y_train_bas, y_test_bas = train_test_split(X, y, test_size=0.2, random_state=42)
X_train_bas.shape, X_test_bas.shape, y_train_bas.shape, y_test_bas.shape


8901 + 2226


X_train_bas.ndim, X_test_bas.ndim, y_train_bas.ndim, y_test_bas.ndim


reg = LazyRegressor(verbose=0, ignore_warnings=False, custom_metric=None)
models, predictions = reg.fit(X_train_bas, X_test_bas, y_train_bas, y_test_bas)

models


from sklearn.ensemble import HistGradientBoostingRegressor
from sklearn.tree import DecisionTreeRegressor
from sklearn.pipeline import make_pipeline


#lr_df = combined_df["others","num_pages"].reset_index(drop=True)


lr_df = combined_df.reset_index(drop=True)


lr_df.head()


X_lr = lr_df
y_lr = combined_df["average_rating"]


X_train_lr, X_test_lr, y_train_lr, y_test_lr = train_test_split(X_lr, y_lr, test_size=0.2,random_state=101)
X_train_lr.shape, X_test_lr.shape, y_train_lr.shape, y_test_lr.shape


model_reg = DecisionTreeRegressor()
model_reg.fit(X_train_lr, y_train_lr)
model_reg.score(X_test_lr, y_test_lr)


y_pred_lr = model_reg.predict(X_test_lr)


from sklearn.metrics import root_mean_squared_error


root_mean_squared_error(y_test_lr,y_pred_lr)


comparison_lr= pd.DataFrame({'Actual': y_test_lr, 'Predicted': y_pred_lr, 'Residual': y_test_lr - y_pred_lr})


comparison_lr





model1 = make_pipeline(MinMaxScaler(), PolynomialFeatures(degree=2), HistGradientBoostingRegressor(random_state=42))
model1.fit(X_train, y_train)
model1.score(X_test, y_test)


y_predict = model1.predict(X_test)


comparison_df= pd.DataFrame({'Actual': y_test, 'Predicted': y_predict, 'Residual': y_test - y_predict})


comparison_df


comparison_df.describe()


comparison_df.info()


comparison_df.shape


comparison_df.isna().sum()


plt.figure(figsize=(12, 6))
sns.kdeplot(comparison_df);


plt.figure(figsize=(12, 6))
sns.set_theme(style="whitegrid");
sns.lineplot(data=comparison_df, palette="tab10", linewidth=2.5);


from yellowbrick.regressor import PredictionError


fig = plt.figure(figsize=(5, 5))
viz = PredictionError(model1)
viz.fit(X_train, y_train)
viz.score(X_test, y_test)
viz.show();


from sklearn.svm import LinearSVR


LinearSVR().get_params()


from sklearn.model_selection import GridSearchCV


HistGradientBoostingRegressor().get_params()


parameters = {'max_features':[0.1, 1.0],'verbose':[0,1,2],'random_state':[0,2],'tol':[1e-05]}
hbr = HistGradientBoostingRegressor()
model3 = GridSearchCV(hbr, parameters, cv=5, scoring='accuracy')
model3.fit(X_train, y_train)


# Access the best hyperparameters found by GridSearchCV
best_params = model3.best_params_


best_params


# Access the best model
best_model = model3.best_estimator_


best_model


best_model.score(X_test, y_test)


fig = plt.figure(figsize=(5, 5))
viz = PredictionError(best_model)
viz.fit(X_train, y_train)
viz.score(X_test, y_test)
viz.show();


#Data cleaning (title, language, date, publisher)
#normalize outliers with robust scaler


data=future_data.copy()


data.head()


data.info()


data.head()


set(data.language_code)





data.drop(["title","isbn","isbn13"],axis=1, inplace=True)


data.head()


data_language_code=pd.get_dummies(data["language_code"],dtype=int)
data_language_code


data_combined=pd.concat([data,data_language_code],axis=1)
data_combined.drop(["language_code"],axis=1, inplace=True)


data_combined["publication_date"] = pd.to_datetime(data_combined["publication_date"], format="%m/%d/%Y", errors='coerce')


data_combined['publication_year'] = data_combined['publication_date'].dt.year
data_combined.drop("publication_date",axis=1,inplace=True)
#df_combined[['publication_month','publication_year']] = df_combined[['publication_month','publication_year']].astype(int)


# Assuming df_combined is your DataFrame
# First, coerce errors to NaT to identify problematic entries
# Check for NaT values to identify problematic entries
problematic_rows = data_combined[data_combined["publication_year"].isna()]

# Inspect problematic rows to understand the issue
problematic_rows

# Further troubleshoot and correct the data as necessary


data_combined['publication_year'].fillna(0000,axis=0,inplace=True)


data_combined["publication_year"]=data_combined["publication_year"].astype(int)


data_combined.head()


data_combined.info()


data_combined.to_csv("processed_data.csv",)


processed_data=pd.read_csv("processed_data.csv",index_col="bookID")


processed_data.head(5)


processed_data.shape


processed_data.info()


processed_data.shape


plt.figure(figsize=(10,6))
sns.heatmap(processed_data.corr(),annot=True,center=True);


X_processed=processed_data.drop("average_rating",axis=1)
y_processed=processed_data["average_rating"]


X_train2, X_test2, y_train2, y_test2=train_test_split(X_processed,y_processed, test_size=0.2,random_state=0)


X_train2.shape, X_test2.shape, y_train2.shape, y_test2.shape


processed_model = LinearRegression()
viz = FeatureImportances(processed_model)
viz.fit(X_processed, y_processed)
viz.show();


processed_model = SGDRegressor()
viz = FeatureImportances(processed_model)
viz.fit(X_processed, y_processed)
viz.show();


processed_model = DecisionTreeRegressor()
viz = FeatureImportances(processed_model)
viz.fit(X_processed, y_processed)
viz.show();


DecisionTreeRegressor().get_params()


model3=DecisionTreeRegressor(random_state=0,splitter="best", max_depth=10, ccp_alpha=1.0,)
model3.fit(X_train2,y_train2)
model3.score(X_test2,y_test2)


fig = plt.figure(figsize=(5, 5))
viz = PredictionError(model3)
viz.fit(X_train2, y_train2)
viz.score(X_test2, y_test2)
viz.show();


reg = LazyRegressor(verbose=0, ignore_warnings=False, custom_metric=None)
models2, predictions2 = reg.fit(X_train2, X_test2, y_train2, y_test2)

models2


from sklearn.ensemble import GradientBoostingRegressor	


GradientBoostingRegressor().get_params()	


model4=GradientBoostingRegressor(random_state=0)
model4.fit(X_train2,y_train2)
model4.score(X_test2,y_test2)


fig = plt.figure(figsize=(5, 5))
viz = PredictionError(model4)
viz.fit(X_train2, y_train2)
viz.score(X_test2, y_test2)
viz.show();


model5=make_pipeline(RobustScaler(),PolynomialFeatures(degree=2),GradientBoostingRegressor(random_state=0))
model5.fit(X_train2,y_train2)


fig = plt.figure(figsize=(5, 5))
viz = PredictionError(model5)
viz.fit(X_train2, y_train2)
viz.score(X_test2, y_test2)
viz.show();


y_predict2=model5.predict(X_test2)


comparison_df_processed= pd.DataFrame({'Actual': y_test2, 'Predicted': y_predict2, 'Residual': y_test2 - y_predict2})


comparison_df_processed


comparison_df_processed.describe()


comparison_df.describe()


from sklearn.metrics import mean_absolute_error


mean_absolute_error(y_test2,y_predict2)


from sklearn.metrics import r2_score


r2_score(y_test2,y_predict2)


r2_score(y_test,y_predict)





processed_data.info()


#for i in processed_data.select_dtypes(exclude=["object"]).columns:
 #   processed_data[i].clip(lower=processed_data[i].quantile(0.15), upper=processed_data[i].quantile(0.85), inplace=True)


#for col in processed_data.select_dtypes(exclude=["object"]).columns:
#    sns.boxplot(x=processed_data[col])
#    plt.show()
    


#data_wo_outliers = processed_data.copy()


#for col in data_wo_outliers.select_dtypes(exclude=["object"]).columns:
#   sns.boxplot(x=data_wo_outliers[col])
#    plt.show()


data_wo_outliers.describe()


X3 = data_wo_outliers.drop("average_rating",axis=1)
y3 = data_wo_outliers["average_rating"]


X_train3, X_test3, y_train3, y_test3 = train_test_split(X3,y3,test_size=0.2, random_state=42)


X_train3.shape, X_test3.shape, y_train3.shape, y_test3.shape


reg3 = LazyRegressor(verbose=0, ignore_warnings=False, custom_metric=None)
models5, predictions5 = reg3.fit(X_train3, X_test3, y_train3, y_test3)

models5


from sklearn.ensemble import GradientBoostingRegressor


model6 = GradientBoostingRegressor(random_state=42)
model6.fit(X_train3, y_train3)


y_pred3 = model6.predict(X_test3)


r2_score(y_test3,y_pred3)


data_wo_dates = data_wo_outliers.drop("publication_year",axis=1)


data_wo_dates.head()


processed_data2=data_wo_dates.reset_index(drop=True)


processed_data2.head()


X4 = processed_data2.drop("average_rating",axis=1)
y4 = processed_data2["average_rating"]


X_train4, X_test4, y_train4, y_test4 = train_test_split(X4,y4,test_size=0.2, random_state=42)


X_train4.shape, X_test4.shape, y_train4.shape, y_test4.shape


reg4 = LazyRegressor(verbose=0, ignore_warnings=False, custom_metric=None)
models6, predictions6 = reg4.fit(X_train4, X_test4, y_train4, y_test4)

models6






